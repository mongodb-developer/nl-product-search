{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7b48655-9a40-427e-9325-9cfe6d58178c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Installing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00267c4a-9b0a-41d8-801a-2cc5b283e0fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a2a9ea0d-10cc-4f4f-bb87-50ed886a8bc0/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /databricks/python3/lib/python3.9/site-packages (from sentence-transformers) (0.14.0+cu117)\n",
      "Requirement already satisfied: numpy in /databricks/python3/lib/python3.9/site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: scipy in /databricks/python3/lib/python3.9/site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in /databricks/python3/lib/python3.9/site-packages (from sentence-transformers) (1.13.0+cu117)\n",
      "Requirement already satisfied: nltk in /databricks/python3/lib/python3.9/site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /databricks/python3/lib/python3.9/site-packages (from sentence-transformers) (4.25.1)\n",
      "Requirement already satisfied: sentencepiece in /local_disk0/.ephemeral_nfs/envs/pythonEnv-a2a9ea0d-10cc-4f4f-bb87-50ed886a8bc0/lib/python3.9/site-packages (from sentence-transformers) (0.1.97)\n",
      "Requirement already satisfied: scikit-learn in /databricks/python3/lib/python3.9/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /databricks/python3/lib/python3.9/site-packages (from sentence-transformers) (0.11.1)\n",
      "Requirement already satisfied: tqdm in /databricks/python3/lib/python3.9/site-packages (from sentence-transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /databricks/python3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
      "Requirement already satisfied: filelock in /databricks/python3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in /databricks/python3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /databricks/python3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
      "Requirement already satisfied: click in /databricks/python3/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /databricks/python3/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /databricks/python3/lib/python3.9/site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-a2a9ea0d-10cc-4f4f-bb87-50ed886a8bc0/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "834c1213-52b0-4d6f-b51b-8cba5f5e2b1e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "844d8aaa-75c2-4661-9a78-dbaeb5089cbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine_sim\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import IDF, HashingTF, RegexTokenizer, StopWordsRemover, Normalizer, Word2Vec\n",
    "from pyspark.sql.functions import (\n",
    "    array_distinct,\n",
    "    col,\n",
    "    collect_list,\n",
    "    concat_ws,\n",
    "    explode,\n",
    "    lit,\n",
    "    map_from_entries,\n",
    "    size,\n",
    "    struct,\n",
    "    sum,\n",
    "    udf,\n",
    "    desc\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    IntegerType,\n",
    "    MapType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    FloatType\n",
    ")\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f84bb1e0-1b83-4213-8164-aab8ed5a6558",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "Out[5]: True"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1872cca8-9e8c-41ac-b9c0-e8056e509892",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Spark configuartion setup, reading data from Mongo Atlas and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44b7185c-ad68-4d11-a012-dd24d36a180d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.appName(\"SearchEngine\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22444f46-6956-4bdc-b0ea-d5a1b73a88ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mongo_uri =  \"mongodb+srv://admin:ddsgrp10@grp10-c1.h89by.mongodb.net\"\n",
    "mongo_db = \"msds697\"\n",
    "mongo_collection = \"products\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3147c0f8-18df-4c47-9221-cc7b7fe1fa70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------------------------------------------------------------+\n",
      "|_id      |brandname  |name                                                          |\n",
      "+---------+-----------+--------------------------------------------------------------+\n",
      "|204234534|A.Kjaerbede|A.Kjaerbede Kaya aviator sunglasses in smoke transparent      |\n",
      "|204234523|A.Kjaerbede|A.Kjaerbede Fame square sunglasses in black                   |\n",
      "|204234586|A.Kjaerbede|A.Kjaerbede Jake flat top round sunglasses in gray transparent|\n",
      "|204234620|A.Kjaerbede|A.Kjaerbede Bror sunglasses in havana                         |\n",
      "|204234621|A.Kjaerbede|A.Kjaerbede Fame square sunglasses in burgundy transparent    |\n",
      "+---------+-----------+--------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = (\n",
    "    ss.read.format(\"com.mongodb.spark.sql.DefaultSource\")\n",
    "    .option(\"spark.mongodb.input.uri\", f\"{mongo_uri}/{mongo_db}.{mongo_collection}\")\n",
    "    .load()\n",
    ")\n",
    "raw.select('_id','brandname','name').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec1489de-e1ca-4180-8984-b2b1c67da91b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "product_metadata = raw.select(\"_id\", \"name\").rdd.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18300ee7-4c8f-4d39-8f89-c5472aa8cf80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer().setPattern(\"\\\\W+\").setInputCol(\"name\").setOutputCol(\"words\")\n",
    "stop_words = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "remover = StopWordsRemover(\n",
    "    inputCol=\"words\", outputCol=\"filtered_words\", stopWords=stop_words\n",
    ")\n",
    "def get_preprocessed_data(raw):\n",
    "    preprocessed_data = tokenizer.transform(raw)\n",
    "    preprocessed_data = remover.transform(preprocessed_data)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11d649af-0e58-4f7d-a9bc-ce3756c7623a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: 26290"
     ]
    }
   ],
   "source": [
    "preprocessed_data = get_preprocessed_data(raw)\n",
    "preprocessed_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15cae34-2062-4ecb-a4a1-8eca627adea0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Product search using TF-IDF and cosine similarity\n",
    "##### In the below code we will do the following things:\n",
    "- Create a UDF to get cosine_similarity between 2 vectors.\n",
    "- Map the product names in our dataset to their term frequencies using HashingTF.\n",
    "- Get the inverse document frequencies of all the products in the dataset using IDF.\n",
    "- For the search term:\n",
    "  - Convert the query string into a Spark Dataframe.\n",
    "  - Get the inverse document frequency of all the terms in the search query.\n",
    "  - Using the UDF cosine_similarity2() calculate the similarity between the search query vector and all the product vectors in the dataframe.\n",
    "- Return the top n products with highest similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89c11fde-c909-4ef6-b168-8d7db7dfdb3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity2(vec1, vec2):\n",
    "    dot_product = float(vec1.dot(vec2))\n",
    "    norm_product = float(vec1.norm(2) * vec2.norm(2))\n",
    "    similarity = dot_product / norm_product if norm_product != 0 else 0.0\n",
    "    return similarity\n",
    "\n",
    "def perform_hashing(processed_data):\n",
    "    hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\", numFeatures=100)\n",
    "    featurizedData = hashingTF.transform(processed_data)\n",
    "    return featurizedData\n",
    "\n",
    "def build_model(processed_data):  \n",
    "    featurized_data = perform_hashing(processed_data)\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(featurized_data)\n",
    "    rescaled_data = idfModel.transform(featurized_data)\n",
    "    return  rescaled_data, idfModel\n",
    "\n",
    "def get_query_vector(query, model):\n",
    "    raw_query = ss.createDataFrame([(query,)], [\"name\"])\n",
    "    processed_query = get_preprocessed_data(raw_query)\n",
    "    featurized_query = perform_hashing(processed_query)\n",
    "    rescaled_query = model.transform(featurized_query)\n",
    "    return rescaled_query\n",
    "\n",
    "def get_tfidf_results(query, data_vector, model, n):\n",
    "    query_vector = get_query_vector(query, model)\n",
    "    search_v = query_vector.select('features').collect()[0][0]\n",
    "    cosine_similarity_udf = udf(lambda x: cosine_similarity2(search_v,x), FloatType())\n",
    "    similarity_df = data_vector.withColumn(\"similarity\", cosine_similarity_udf(data_vector[\"features\"]))\n",
    "    similar_products = similarity_df.orderBy(desc(\"similarity\")).select('name', 'similarity').limit(n).collect()\n",
    "    products = [x.name for x in similar_products]\n",
    "    return products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f334633b-fd51-4cdd-bda6-ea198a164a87",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Product Search using Word2Vec\n",
    "\n",
    "###### Steps followed:\n",
    " - Build a Word2Vec Model by training on the corpus of prepocessed product data that we have\n",
    " - Transform the input products data into high dim vectors\n",
    " - We transform the search query into a vector using the same model and preprocessing as above.\n",
    " - Use cosine similarity to get the similarity between the search query and product data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6a57de0-7ac5-4003-8136-6e3e9a7ae3f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_word2vec_model(preprocessed_data):\n",
    "    \n",
    "    \n",
    "    word2vec = Word2Vec(\n",
    "        vectorSize=100, minCount=5, inputCol=\"filtered_words\", outputCol=\"result\"\n",
    "    )\n",
    "    model = word2vec.fit(preprocessed_data)\n",
    "    result = model.transform(preprocessed_data)\n",
    "\n",
    "    return result, model\n",
    "\n",
    "def build_search_vec(model, search_query):\n",
    "    search_df = sc.parallelize([(1, search_query)]).toDF([\"id\", \"name\"])\n",
    "\n",
    "    query_df = tokenizer.transform(search_df)\n",
    "    query_df = remover.transform(query_df)\n",
    "\n",
    "    # run word2vec model on input string\n",
    "    search_query_vec = model.transform(query_df)\n",
    "    search_query_vec = search_query_vec.select(\"result\")\n",
    "\n",
    "    return search_query_vec\n",
    "  \n",
    "def get_word2vec_results(search_query, model, master_data, n):\n",
    "    search_query_vec = build_search_vec(model, search_query).collect()[0][0]\n",
    "    cosine_similarity_udf2 = udf(\n",
    "        lambda x: cosine_similarity2(search_query_vec, x), FloatType()\n",
    "    )\n",
    "    similarity_df = master_data.withColumn(\n",
    "        \"similarity\", cosine_similarity_udf2(master_data[\"result\"])\n",
    "    )\n",
    "    similar_products = (\n",
    "        similarity_df.sort(\"similarity\", ascending=False)\n",
    "        .select(\"name\", \"similarity\")\n",
    "        .limit(10)\n",
    "        .collect()\n",
    "    )\n",
    "    products = [x.name for x in similar_products]\n",
    "    return products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9533965b-1568-4b43-8050-0bd39e2b884b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Product Search using BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "852d74e9-cb51-4708-a281-b0d34560d1be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We use Pyspark to create an inverted index to perform BM25. Here is the overview of the steps:\n",
    "1. Preprocessing:<br>\n",
    "  a) We use Pyspark transformers like RegexTokenizer, StopwordsRemover to preprocess the data.<br>\n",
    "  b) We have also created a UDF to use stemming from nltk library to convert every word to its canonical form.<br>\n",
    "  \n",
    "2. Inverted index:<br>\n",
    "Once the data is preprocessed, we start with the indexing phase.<br>\n",
    "  a) During the indexing phase, we generate two distinct dictionaries by iterating through all the documents and appending new entries.<br>\n",
    "  b) The first dictionary is an inverted index with words serving as keys and a dictionary of document numbers and occurrence rate as values. <br>\n",
    "  c) The second dictionary is a word counter index, which stores the length of all documents. <br>\n",
    "\n",
    "Here are some examples of how the dictionaries are structured:\n",
    "\n",
    "Inverted index: {\"word1\" : {\"document1\" : 1, \"document2\": 3}, \"word2\" : {\"document5\" : 1}}\n",
    "\n",
    "Word counter: {\"document1\" : 21}\n",
    "<br><br>\n",
    "2) In addition to two dictionaries, we also compute several metrics such as the total number of documents and the total number of words in all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5724f72-59d7-4efd-b62a-e43361b3606d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def stemming(words):\n",
    "    result = []\n",
    "    for w in words:\n",
    "        root_word = ps.stem(w)\n",
    "        result.append(root_word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73a696ab-78db-41d7-8d63-67e1d96e5cdc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 5417\n",
      "Total words: 192210\n"
     ]
    }
   ],
   "source": [
    "stemming_udf = udf(lambda x: stemming(x), ArrayType(elementType=StringType()))\n",
    "\n",
    "preprocessed_data = preprocessed_data.withColumn(\n",
    "    \"tokens\", stemming_udf(\"filtered_words\")\n",
    ")\n",
    "\n",
    "# Flatten the list of tokens into individual words\n",
    "words = preprocessed_data.select(explode(\"tokens\").alias(\"word\"))\n",
    "\n",
    "# Count total unique words and total words\n",
    "total_unique_words = words.select(\"word\").distinct().count()\n",
    "total_words = words.count()\n",
    "\n",
    "print(\"Total unique words:\", total_unique_words)\n",
    "print(\"Total words:\", total_words)\n",
    "\n",
    "# Define UDFs to tokenize the product names and count the occurrences of each word in a document\n",
    "word_count = udf(lambda s: Counter(s), MapType(StringType(), IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11410255-7a14-48b6-ba8c-da237a90e48d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert _id field to string\n",
    "id_str = concat_ws(\"\", col(\"_id\").cast(StringType()))\n",
    "\n",
    "# Tokenize the product names and group by word and document\n",
    "word_count_df = (\n",
    "    preprocessed_data.select(\"_id\", explode(\"tokens\").alias(\"word\"))\n",
    "    .groupBy(\"word\", \"_id\")\n",
    "    .agg(size(collect_list(\"word\")).alias(\"occurrence\"))\n",
    "    .groupBy(\"word\")\n",
    "    .agg(\n",
    "        map_from_entries(collect_list(struct(id_str.alias(\"id\"), \"occurrence\"))).alias(\n",
    "            \"documents\"\n",
    "        )\n",
    "    )\n",
    "    .withColumnRenamed(\"word\", \"_id\")\n",
    ").rdd.map(lambda row: (row[\"_id\"], row[\"documents\"]))\n",
    "\n",
    "inverted_index = word_count_df.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbafaedf-5094-45bf-a8a4-b0e3bd09d0b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compute the length of all documents\n",
    "doc_length_df = (\n",
    "    preprocessed_data.select(\"_id\", size(\"tokens\").alias(\"length\"))\n",
    "    .groupBy(\"_id\")\n",
    "    .agg(sum(col(\"length\")).alias(\"doc_length\"))\n",
    "    .withColumn(\"_id\", concat_ws(\"\", col(\"_id\").cast(StringType())))\n",
    "    .rdd.map(lambda row: (row[\"_id\"], row[\"doc_length\"]))\n",
    ")\n",
    "doc_length = doc_length_df.collectAsMap()\n",
    "\n",
    "doc_length[\"word_counter\"] = total_unique_words\n",
    "doc_length[\"doc_counter\"] = total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d9e9dac-4f8e-4edf-80dc-0577c9e4e741",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compute the unique word count for each document\n",
    "unique_word_count_df = preprocessed_data.select(\n",
    "    \"_id\",\n",
    "    size(array_distinct(\"tokens\")).alias(\"num_unique_words\"),\n",
    ").withColumn(\"_id\", concat_ws(\"\", col(\"_id\").cast(StringType()))).rdd.map(lambda row: (row[\"_id\"], row[\"num_unique_words\"]))\n",
    "unique_word = unique_word_count_df.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbbcfb9f-d915-4d33-9135-b5572b6bba44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Term Frequency\n",
    "def tf(word_occ, word_count):\n",
    "    return word_occ / word_count\n",
    "\n",
    "\n",
    "# Inverse Document Frequency\n",
    "def idf(total_doc_count, doc_count_cont_word):\n",
    "    return math.log(total_doc_count / doc_count_cont_word)\n",
    "\n",
    "\n",
    "# TF-IDF\n",
    "def tf_idf(word_occ, word_count, total_doc_count, doc_count_cont_word):\n",
    "    return tf(word_occ, word_count) * idf(total_doc_count, doc_count_cont_word)\n",
    "\n",
    "\n",
    "# Average Document Length\n",
    "def avgdl(total_word_count, total_doc_count):\n",
    "    return total_word_count / total_doc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "543d463b-3609-4c5e-adc7-8e5d06176e7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# BM25\n",
    "def bm25(\n",
    "    word_occurrences,\n",
    "    word_count,\n",
    "    document_count,\n",
    "    documents_containing_word,\n",
    "    all_document_word_count,\n",
    "    b=0.75,\n",
    "    k=1.2,\n",
    "):\n",
    "    _idf = idf(document_count, documents_containing_word)\n",
    "    _tf = tf(word_occurrences, word_count)\n",
    "    _avg_dl = avgdl(all_document_word_count, document_count)\n",
    "\n",
    "    score = _idf * (_tf * (k + 1)) / (_tf + k * (1 - b + b * word_count / _avg_dl))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e71c603-3c07-4657-a524-1ce54e97dd16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define a regex pattern to split text into words\n",
    "pattern = r\"[^a-zA-Z0-9]+\"\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "# Define a function to preprocess the product names\n",
    "def preprocess(text):\n",
    "    words = re.split(pattern, text.lower())\n",
    "    tokens = [w for w in words if w]\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "    res = []\n",
    "    for w in words:\n",
    "        res.append(ps.stem(w))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffd938c3-8ebc-47d7-b509-a6fdfb2c2b6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_bm25_results(query, top_n):\n",
    "    text = preprocess(query)\n",
    "    topic_words = {}\n",
    "\n",
    "    for word in text:\n",
    "        topic_words[word] = topic_words.get(word, 0) + 1\n",
    "\n",
    "    n = len(text)\n",
    "\n",
    "    results = score(n, topic_words)\n",
    "    results_ranked = dict(sorted(results.items(), key=lambda item: item[1], reverse=True))\n",
    "    products = [product_metadata[int(id)] for id in list(results_ranked.keys())[:top_n]]\n",
    "    \n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63a09b09-0bf7-4f3f-afa2-a8efb2d6a52a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def score(n, topic_words):\n",
    "    scores = {}\n",
    "    for word, occurrence in topic_words.items():\n",
    "        word_score = bm25(\n",
    "            occurrence,\n",
    "            n,\n",
    "            doc_length[\"doc_counter\"],\n",
    "            len(inverted_index.get(word, [])) + 1,\n",
    "            doc_length[\"word_counter\"],\n",
    "        )\n",
    "        for doc_id, doc_occurrence in inverted_index.get(word, {}).items():\n",
    "            doc_score = bm25(\n",
    "                doc_occurrence,\n",
    "                doc_length[doc_id],\n",
    "                doc_length[\"doc_counter\"],\n",
    "                len(inverted_index.get(word, [])) + 1,\n",
    "                doc_length[\"word_counter\"],\n",
    "            )\n",
    "            if scores.get(doc_id) == None:\n",
    "                scores[doc_id] = word_score * doc_score\n",
    "            else:\n",
    "                scores[doc_id] = scores[doc_id] + word_score * doc_score\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20b96a60-dd4f-4e49-9e0b-c467ffbe900b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Product search using sentence transformer and cosine similarity\n",
    "\n",
    "##### In the below code we will do the following things:\n",
    "- Create embeddings for all the products in our mongoDB collection, using sentence tranformer's all-MiniLM-L6-v2 (BERT) model.\n",
    "- Create embedding for the query term from the same model.\n",
    "- Get the similarity scores with each product for the query term using sklearn's cosine similarity.\n",
    "- Return the top n similar products as recommendation for the query term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb7f5b01-7fc1-4e93-accd-c8626896f746",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "product_names = raw.select('name').rdd.map(lambda x: str(x['name'])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7e9e649-f1c9-47de-a57b-967b9b6209c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac74c467c4f54a33bc38c8b4bc60ddb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "ac74c467c4f54a33bc38c8b4bc60ddb1",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4482ebdfeed04d2695c6c893d7f3b85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "4482ebdfeed04d2695c6c893d7f3b85e",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9e15727bdc4abd9c3cfa9efd9bf70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "8a9e15727bdc4abd9c3cfa9efd9bf70b",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84156146900479e92514f1959ee58f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "a84156146900479e92514f1959ee58f9",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710f6cd5193f46f69410b12486d9f851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "710f6cd5193f46f69410b12486d9f851",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3992f0245c7941e8b6b02a39e52a13aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "3992f0245c7941e8b6b02a39e52a13aa",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07b6f8d5df041608c9712cd6fe71538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "f07b6f8d5df041608c9712cd6fe71538",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8b56e3fb9343c4bdf772bda8acceee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "0c8b56e3fb9343c4bdf772bda8acceee",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d2bec2ccad4f11a4b5bc88c196fd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "e4d2bec2ccad4f11a4b5bc88c196fd97",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496dce3309414926b47e7e6a0b8ec67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "496dce3309414926b47e7e6a0b8ec67a",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f068a6cb1a04ee29aa254795e1e36fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "1f068a6cb1a04ee29aa254795e1e36fb",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9ea71d47804e7da7a9556b4a8cc833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "4c9ea71d47804e7da7a9556b4a8cc833",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2121e65234ac4e09a02f21c0e3e4c4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "2121e65234ac4e09a02f21c0e3e4c4b1",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c24442fa053484c998bc7c532af07fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.jupyter.widget-view+json": {
         "model_id": "8c24442fa053484c998bc7c532af07fa",
         "version_major": 2,
         "version_minor": 0
        },
        "text/plain": "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "73587051-abc4db860236e83c6433c615"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_bert = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "def get_BERT_embeddings(sentences,model):\n",
    "    embeddings = model.encode(sentences)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a5b9664-28c0-4f1b-a5cd-ede43d71d917",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "name_embeddings = get_BERT_embeddings(product_names,model_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bc9c701-5933-49cf-985a-2fe9db713bd6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_BERT_results(query, n):\n",
    "    query_embeddings = get_BERT_embeddings([query],model_bert)\n",
    "    similarities = cosine_sim(query_embeddings, name_embeddings)\n",
    "    similarities = similarities.flatten()\n",
    "    indices = (-similarities).argsort()[1:11]\n",
    "    similar_product_names = [product_names[i] for i in indices]\n",
    "    return similar_product_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9be26d1e-1268-4b17-941f-4e690308d4f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Search comparisons\n",
    "### Query - \"sneakers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86fb5df5-9760-4f66-b0ff-1facc160632d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_search_results(query, model_type, n=10):\n",
    "    start_time = time.time()\n",
    "    if model_type == 'bert':\n",
    "        results = get_BERT_results(query, n)\n",
    "    elif model_type == 'bm25':\n",
    "        results = get_bm25_results(query, n)\n",
    "    elif model_type == 'tfidf':\n",
    "        data, model = build_model(preprocessed_data)\n",
    "        results = get_tfidf_results(query, data, model, n)\n",
    "    else:\n",
    "        data, model = build_word2vec_model(preprocessed_data)\n",
    "        results = get_word2vec_results(query, model, data, n)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken: {end_time - start_time} seconds\\n\")\n",
    "    print(f\"Your search query: {query}\")\n",
    "    for i, pd in enumerate(results):\n",
    "        print(f\"{i}. {pd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cbdd741-91c1-4ca7-9ac4-29b208090ea8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.004667997360229492 seconds\n",
      "\n",
      "Your search query: sneakers\n",
      "0. Bershka sneakers in white\n",
      "1. Bershka sneakers in white\n",
      "2. Office sneakers in white\n",
      "3. Bershka sneakers in white\n",
      "4. Bershka lace up sneakers black\n",
      "5. Vans Cruze Too sneakers in gray\n",
      "6. Vans Lowland sneakers in off-white\n",
      "7. Nike Daybreak sneakers in black\n",
      "8. Bershka runner sneakers in gray\n",
      "9. Lacoste L005 Sneakers In White\n"
     ]
    }
   ],
   "source": [
    "query = \"sneakers\"\n",
    "get_search_results(query, \"bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d403830c-658f-48cc-8c05-54471f13437d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 11.02399206161499 seconds\n",
      "\n",
      "Your search query: sneakers\n",
      "0. Vans Authentic Sneakers In Black\n",
      "1. Vans Authentic Sneakers In Triple Black\n",
      "2. Vans Authentic sneakers in white\n",
      "3. Vans Authentic sneakers in white\n",
      "4. Vans Authentic sneakers in triple white\n",
      "5. Vans Authentic sneakers in mid green\n",
      "6. Vans Authentic sneakers in true white\n",
      "7. ALDO Mabel platform boots in black patent\n",
      "8. Lacoste T-clip sneakers in white\n",
      "9. Nike Vapormax 2021 Flyknit sneakers in triple black\n"
     ]
    }
   ],
   "source": [
    "query = \"sneakers\"\n",
    "get_search_results(query, \"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c1b9f18-da98-47e8-8545-bc0830308d92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 11.01742696762085 seconds\n",
      "\n",
      "Your search query: sneakers\n",
      "0. Schuh willis sneakers in white\n",
      "1. schuh warner cupsole sneakers in white\n",
      "2. Office Carlton sneakers in white\n",
      "3. Office sneakers in white\n",
      "4. SikSilk court lauda sneakers in white\n",
      "5. Vans Lowland sneakers in rust\n",
      "6. Ben Sherman target retro sneakers\n",
      "7. Bershka sneakers in white\n",
      "8. Bershka sneakers in white\n",
      "9. Bershka sneakers in white\n"
     ]
    }
   ],
   "source": [
    "query = \"sneakers\"\n",
    "get_search_results(query, \"word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e28e14d-825b-4a24-83b8-898fc138e025",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.09334158897399902 seconds\n",
      "\n",
      "Your search query: sneakers\n",
      "0. Public Desire ambush sneakers in off white black\n",
      "1. Public Desire ambush sneakers in khaki black\n",
      "2. Public Desire ambush sneakers in khaki black\n",
      "3. Vans SK8-Hi sneakers in black\n",
      "4. Vans x MOCA Frances Stark Sk8-Hi sneakers in black\n",
      "5. Converse Run Star Motion platform sneakers in black\n",
      "6. Vans Old Skool sneakers in black and white\n",
      "7. Vans Sk8-Hi sneakers in green bandana print\n",
      "8. Vans SK8-Hi printed sneakers in black and white\n",
      "9. The North Face Wayroute sneakers in black\n"
     ]
    }
   ],
   "source": [
    "query = \"sneakers\"\n",
    "get_search_results(query, \"bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef58ec6e-42a5-4e53-997e-f1947616ee7b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Query - \"tshirt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15775379-effd-4b8a-b6b2-f1c4526b1502",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 6.088217496871948 seconds\n",
      "\n",
      "Your search query: tshirt\n",
      "0. Emporio Armani microfiber trunk in black\n",
      "1. Emporio Armani microfiber thong in navy\n",
      "2. Element Spores t-shirt in black\n",
      "3. Hollister sport highlight logo cuffed sweatpants in black\n",
      "4. AllSaints underground T-shirt in white\n",
      "5. Emporio Armani 3 pack sneaker socks in white/black/blue\n",
      "6. Aria Cove sheer wrap shirt mini dress in purple\n",
      "7. Element Hollis T-shirt in white\n",
      "8. Element Bazan t-shirt in black\n",
      "9. Element Groman t-shirt in white\n"
     ]
    }
   ],
   "source": [
    "query = \"tshirt\"\n",
    "get_search_results(query, \"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "962b368c-368b-4fee-a93b-a2457bc6b833",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 8.485763788223267 seconds\n",
      "\n",
      "Your search query: tshirt\n",
      "0. A.Kjaerbede Kaya aviator sunglasses in smoke transparent\n",
      "1. A.Kjaerbede Fame square sunglasses in black\n",
      "2. A.Kjaerbede Jake flat top round sunglasses in gray transparent\n",
      "3. A.Kjaerbede Bror sunglasses in havana\n",
      "4. A.Kjaerbede Fame square sunglasses in burgundy transparent\n",
      "5. A.Kjaerbede Marvin round sunglasses in smoke transparent\n",
      "6. A.Kjaerbede Kaws sunglasses in demi tortoise\n",
      "7. A.Kjaerbede Marvin round sunglasses in champagne\n",
      "8. A.Kjaerbede Bate square sunglasses in champagne\n",
      "9. A.Kjaerbede Bror rectangle sunglasses in demi tortoise\n"
     ]
    }
   ],
   "source": [
    "query = \"tshirt\"\n",
    "get_search_results(query, \"word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5ab6003-ce56-435c-820f-38ca9608b729",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.0005068778991699219 seconds\n",
      "\n",
      "Your search query: tshirt\n",
      "0. PS Paul Smith zebra photos tshirt in black\n"
     ]
    }
   ],
   "source": [
    "query = \"tshirt\"\n",
    "get_search_results(query, \"bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c890ea08-8275-4b05-af0c-f887634e93bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.05975985527038574 seconds\n",
      "\n",
      "Your search query: tshirt\n",
      "0. Threadbare raglan T-shirt in gray black\n",
      "1. AllSaints Swoopy graphic t-shirt in washed black\n",
      "2. Tommy Hilfiger lightweight twill overshirt in tan\n",
      "3. Lacoste plain t-shirt in blue\n",
      "4. Threadbare Plus 2 pack raglan T-shirt in navy blue & white navy\n",
      "5. Threadbare 2 pack raglan T-shirt in navy blue & white navy\n",
      "6. AllSaints Tonic ramskull logo t-shirt in washed black\n",
      "7. Threadbare pocket t-shirt in black\n",
      "8. Boss Athleisure Tee 2 T-shirt in blue\n",
      "9. Bolongaro Trevor Sport mesh t-shirt in gray\n"
     ]
    }
   ],
   "source": [
    "query = \"tshirt\"\n",
    "get_search_results(query, \"bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "306f0d68-64b8-46c8-ad78-bd6ccd8db2b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Query - \"chappals\" which means sandals/slippers in Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8d4eed3-0a38-4aeb-992d-9a615ecc3fbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 5.9766223430633545 seconds\n",
      "\n",
      "Your search query: chappals\n",
      "0. MAC Lip Pencil - Edge To Edge\n",
      "1. Only & Sons Edge loose fit chinos in brown\n",
      "2. Fila T-shirt with logo in blue\n",
      "3. Billabong Range t-shirt in black\n",
      "4. Only & Sons edge loose fit jeans in gray wash\n",
      "5. Fila t-shirt with logo in green\n",
      "6. Billabong Shine T-shirt in black\n",
      "7. Only & Sons Edge loose fit jeans in mid wash\n",
      "8. Dickies Porterdale t-shirt in white\n",
      "9. Only & Sons Edge loose fit jeans in light wash\n"
     ]
    }
   ],
   "source": [
    "query = \"chappals\"\n",
    "get_search_results(query, \"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "496961b2-d35a-42da-a626-771c5e26e324",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 8.383044242858887 seconds\n",
      "\n",
      "Your search query: chappals\n",
      "0. A.Kjaerbede Kaya aviator sunglasses in smoke transparent\n",
      "1. A.Kjaerbede Fame square sunglasses in black\n",
      "2. A.Kjaerbede Jake flat top round sunglasses in gray transparent\n",
      "3. A.Kjaerbede Bror sunglasses in havana\n",
      "4. A.Kjaerbede Fame square sunglasses in burgundy transparent\n",
      "5. A.Kjaerbede Marvin round sunglasses in smoke transparent\n",
      "6. A.Kjaerbede Kaws sunglasses in demi tortoise\n",
      "7. A.Kjaerbede Marvin round sunglasses in champagne\n",
      "8. A.Kjaerbede Bate square sunglasses in champagne\n",
      "9. A.Kjaerbede Bror rectangle sunglasses in demi tortoise\n"
     ]
    }
   ],
   "source": [
    "query = \"chappals\"\n",
    "get_search_results(query, \"word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f820644d-5d20-47e0-9dd4-6231c13e242d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00032210350036621094 seconds\n",
      "\n",
      "Your search query: chappals\n"
     ]
    }
   ],
   "source": [
    "query = \"chappals\"\n",
    "get_search_results(query, \"bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcd5cef0-82ab-4b6a-a3e0-954fe856c4de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.05839347839355469 seconds\n",
      "\n",
      "Your search query: chappals\n",
      "0. Puma Scuff sherpa slippers in white\n",
      "1. Buffalo Cloud Chai Vegan Sneakers In Black\n",
      "2. Buffalo vegan cloud chai chunky sneakers in black\n",
      "3. Buffalo vegan cloud chai chunky sneakers in black\n",
      "4. Puma Scuff sherpa slippers in black\n",
      "5. Crocs Jibbitz faces 5 pack\n",
      "6. Crocs Jibbitz led fun 5 pack\n",
      "7. Kickers Daltrey chukka boots in rust\n",
      "8. Ben Sherman lace-up stripe sole canvas sneakers in chambray\n",
      "9. UGG fluff slippers in black\n"
     ]
    }
   ],
   "source": [
    "query = \"chappals\"\n",
    "get_search_results(query, \"bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "073aa62e-abe1-4b6b-8255-417cb09579c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "After comparing the performance of different algorithms on the \"sneakers\", \"tshirt\", and \"chappals\" queries, we can conclude that each algorithm varies in terms of speed and relevance of results.\n",
    "1. For the \"sneakers\" query, the BM25 algorithm is the fastest with relevant results returned quickly. The TFIDF and Word2Vec algorithms are slower to return results, while the Bert algorithm is slower than BM25 with relevant results.\n",
    "2. However, for the \"tshirt\" and \"chappals\" queries, the BM25 algorithm has the best time complexity but yields unsatisfactory results due to the limited vocabulary of the corpus. The Word2Vec algorithm has low time performance with low relevance of results. TFIDF has similar performance as Word2Vec. The Bert algorithm has intermediate performance with highly relevant results.\n",
    "\n",
    "From the execution time and meaningfulness of the search results, we find that BERT is the best model since it is built upon a large corpus of data and can handle search queries in multiple languages. BM25 is the fastest method and is the most scalable."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Group_10_Task_3",
   "notebookOrigID": 4205848236188216,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
